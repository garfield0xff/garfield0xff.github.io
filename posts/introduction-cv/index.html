<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Introduction Computer Vision | Synapse</title>
<meta name="keywords" content="">
<meta name="description" content="컴퓨터 비전에 대해 원론적으로 접근해보면서 컴퓨터 비전에 대한 Depth를 넓히고자 한다 .
정의 디지털 이미지에서 정보를 추출하는 과학적인 영역 여기서 말하는 정보란 (Space, Location.. ) 등의 새로운 차원의 정보를 말한다. 따라서 RGB 혹은 RGBA 데이터로 새로운 차원의 정보를 추출하는 과학적인 영역이라고 해석할 수 있다
인간의 시야와 비슷한 시야 인지 능력을 구현하는 학문 인간의 지각 능력과 인지(해석)능력을 구분해 파이프라인을 구현하고 시야인지 능력을 구현하고자 하는 학문이라고 해석할 수 있다.
아래 이미지를 통해 컴퓨터 비전이 포맷에 따라 어떻게 사용되는지 간략하게 파악 할 수 있다.">
<meta name="author" content="">
<link rel="canonical" href="https://garfield0xff.github.io/posts/introduction-cv/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://garfield0xff.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://garfield0xff.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://garfield0xff.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://garfield0xff.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://garfield0xff.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://garfield0xff.github.io/posts/introduction-cv/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:title" content="Introduction Computer Vision" />
<meta property="og:description" content="컴퓨터 비전에 대해 원론적으로 접근해보면서 컴퓨터 비전에 대한 Depth를 넓히고자 한다 .
정의 디지털 이미지에서 정보를 추출하는 과학적인 영역 여기서 말하는 정보란 (Space, Location.. ) 등의 새로운 차원의 정보를 말한다. 따라서 RGB 혹은 RGBA 데이터로 새로운 차원의 정보를 추출하는 과학적인 영역이라고 해석할 수 있다
인간의 시야와 비슷한 시야 인지 능력을 구현하는 학문 인간의 지각 능력과 인지(해석)능력을 구분해 파이프라인을 구현하고 시야인지 능력을 구현하고자 하는 학문이라고 해석할 수 있다.
아래 이미지를 통해 컴퓨터 비전이 포맷에 따라 어떻게 사용되는지 간략하게 파악 할 수 있다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://garfield0xff.github.io/posts/introduction-cv/" />
<meta property="og:image" content="https://garfield0xff.github.io/images/papermod-cover.png" />
<meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-29T23:16:38+09:00" />
<meta property="article:modified_time" content="2024-07-29T23:16:38+09:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://garfield0xff.github.io/images/papermod-cover.png" />
<meta name="twitter:title" content="Introduction Computer Vision"/>
<meta name="twitter:description" content="컴퓨터 비전에 대해 원론적으로 접근해보면서 컴퓨터 비전에 대한 Depth를 넓히고자 한다 .
정의 디지털 이미지에서 정보를 추출하는 과학적인 영역 여기서 말하는 정보란 (Space, Location.. ) 등의 새로운 차원의 정보를 말한다. 따라서 RGB 혹은 RGBA 데이터로 새로운 차원의 정보를 추출하는 과학적인 영역이라고 해석할 수 있다
인간의 시야와 비슷한 시야 인지 능력을 구현하는 학문 인간의 지각 능력과 인지(해석)능력을 구분해 파이프라인을 구현하고 시야인지 능력을 구현하고자 하는 학문이라고 해석할 수 있다.
아래 이미지를 통해 컴퓨터 비전이 포맷에 따라 어떻게 사용되는지 간략하게 파악 할 수 있다."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://garfield0xff.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Introduction Computer Vision",
      "item": "https://garfield0xff.github.io/posts/introduction-cv/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Introduction Computer Vision",
  "name": "Introduction Computer Vision",
  "description": "컴퓨터 비전에 대해 원론적으로 접근해보면서 컴퓨터 비전에 대한 Depth를 넓히고자 한다 .\n정의 디지털 이미지에서 정보를 추출하는 과학적인 영역 여기서 말하는 정보란 (Space, Location.. ) 등의 새로운 차원의 정보를 말한다. 따라서 RGB 혹은 RGBA 데이터로 새로운 차원의 정보를 추출하는 과학적인 영역이라고 해석할 수 있다\n인간의 시야와 비슷한 시야 인지 능력을 구현하는 학문 인간의 지각 능력과 인지(해석)능력을 구분해 파이프라인을 구현하고 시야인지 능력을 구현하고자 하는 학문이라고 해석할 수 있다.\n아래 이미지를 통해 컴퓨터 비전이 포맷에 따라 어떻게 사용되는지 간략하게 파악 할 수 있다.",
  "keywords": [
    
  ],
  "articleBody": "컴퓨터 비전에 대해 원론적으로 접근해보면서 컴퓨터 비전에 대한 Depth를 넓히고자 한다 .\n정의 디지털 이미지에서 정보를 추출하는 과학적인 영역 여기서 말하는 정보란 (Space, Location.. ) 등의 새로운 차원의 정보를 말한다. 따라서 RGB 혹은 RGBA 데이터로 새로운 차원의 정보를 추출하는 과학적인 영역이라고 해석할 수 있다\n인간의 시야와 비슷한 시야 인지 능력을 구현하는 학문 인간의 지각 능력과 인지(해석)능력을 구분해 파이프라인을 구현하고 시야인지 능력을 구현하고자 하는 학문이라고 해석할 수 있다.\n아래 이미지를 통해 컴퓨터 비전이 포맷에 따라 어떻게 사용되는지 간략하게 파악 할 수 있다.\n이해 위 정의를 통해 컴퓨터 비전을 이해한다는 것은 인간의 시야 인지 능력을 컴퓨터로 구현하는 것을 이해해야한다 라고도 해석 할 수 있을 것이다. 그러면 순차적으로 어떤 것들을 이해해야 하는지 살펴보자.\ncomputer science : memory, data structure 등 이미지를 처리하는 자료구조 및 메모리에 대한 기본적인 이해가 필요하다. algorithm : Filtering, Edge Detection 등 이미지 전처리를 위한 전통적인 알고리즘 기법을 이해해야한다. machine learning: 다양한 조건에서 나오는 이미지 패턴에 대한 일반화, 복잡한 연산을 통한 특징점 검출, 복잡한 이미지 패턴을 추출하기 위해 maching learning 알고리즘에 대한 기본적인 이해가 필요하다. 그렇다면 machine learning은 컴퓨터 비전에서 어떻게 설계 되었을까? 인간의 sensing device와 interpreting device를 구분해서 해석하고 알고리즘으로 구현한 것이 machine learning의 기본 원리라고 이해 할 수 있다. 아래 인간의 시야 인지 파이프라인을 간략화한 그림을 통해 컴퓨터 비전이 어떻게 처리되는지 간단하게 이해해보자.\n파이프라인 빛이 인간의 눈에 들어오면 망막의 시세포가 빛을 신경 신호로 변환해준다. 여기서 변환된 신경 신호는 외측 슬상체를 통해 두 눈에서 들어온 신호를 결합하고 신호정보의 전처리와 필터링을 수행해준다.\n전처리된 정보는 1차 시각야에서 윤곽을 추출해주는 방위 선택성 뉴런에 반응하게 된다. 방위 선택성 뉴런은 반응하는 방식에 따라 단순형 세포와 복잡형 세포로 나뉜다. 단순형 세포는 특정 위치와 특정 방향에 정확하게 위치한 선에 반응하고 복잡형 세포는 시야 어느 위치에 있든 특정 방향으로 기울어진 선에 반응하게 된다. 따라서 단순형 세포는 밝은 영역과 어두운 영역을 명확히 구분하는데 도움을 주고 복잡형 세포는 움직이는 물체나 선의 연속적인 변화를 인식하는데 도움을 준다. 딥러닝 알고리즘 중 CNN에서 Convolution 연산이 단순형 세포의 역활을 하고 Polling 연산이 복잡한 세포의 역활을 맡는다고도 생각 할 수 있다.\n2차 시각야에서는 1차 시각야에서 추출된 윤곽 및 시각 특징들의 정보를 통합하고 제 4차 시각야로 보내준다. (2차 시각야에서도 1차 시각야의 방위선택성 뉴런이 존재하여 이미지 윤곽을 추출하는 역활을 하지만 주요 역활은 시각 정보 특징들의 정보를 통합하는 것이라고 이해 할 수 있다.)\n4차 시각야에서는 통합된 정보를 바탕으로 색상, 형태 ,물체를 인식하고 물체에 대한 이해 및 상위 피질과의 중계 역활을 한다. 따라서 인간의 interpreting device의 역활을 일부 수행한다고 볼 수 있다 .\n파이프라인 정리 정리해보면 다음과 같다.\n망막 : 빛을 신경 세포로 변환 외측 슬상체 : 신호 결합 및 전처리 1차 시각야 : 신호 정보에 대한 윤곽 및 시야정보 추출 2차 시각야: 시야 정보 통합 및 고차원 시야 정보 추출 4차 시각야: 고차원의 시야 정보를 바탕으로 색상, 형태, 물체 인식 및 분류 및 상위 피질과의 중계 우리는 이것을 컴퓨터 프로세스에 대입해서 생각해 볼 수 있다.\n카메라 센서 및 광학 센서 ( 망막 ) : 빛을 전자 신호로 변환 아날로그-디지털 변환 ( 외측 슬상체 ): 전자 신호를 이미지 데이터로 변환 및 전처리 윤곽 추출 알고리즘 ( 1차 시각야 ) : 이미지 데이터에 윤곽 추출 알고리즘을 거쳐 윤곽 생성 ex) CNN, ResNet… 시야 정보 통합 알고리즘 ( 2차 시각야 ) : 추출한 정보 데이터를 통합하고 고차원의 시야정보 생성 ex) CNN, ResNet.. 색상, 형태, 물체 인식 알고리즘 ( 4차 시각야 ) : 고차원의 시야정보로 물체를 인식 혹은 판별 ex) R-CNN, YOLO, CNN, GAN.. 위의 인지 프로세스를 이해했다면 아래 CNN의 과정을 대략적으로 이해 할 수 있을 것이다.\n다음시간에는 딥러닝 및 머신러닝의 기본 원리, 학습의 의미를 표현하고 있는 Linear Regression에 대해 알아보고자 한다.\n참고 : standford computer vision lab,helloT\n이미지 출처 : Analytics Vidhya, standford computer vision lab, helloT\n",
  "wordCount" : "577",
  "inLanguage": "en",
  "image": "https://garfield0xff.github.io/images/papermod-cover.png","datePublished": "2024-07-29T23:16:38+09:00",
  "dateModified": "2024-07-29T23:16:38+09:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://garfield0xff.github.io/posts/introduction-cv/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Synapse",
    "logo": {
      "@type": "ImageObject",
      "url": "https://garfield0xff.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://garfield0xff.github.io/" accesskey="h" title="Synapse (Alt + H)">Synapse</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://garfield0xff.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://garfield0xff.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Introduction Computer Vision
    </h1>
    <div class="post-meta"><span title='2024-07-29 23:16:38 +0900 KST'>July 29, 2024</span>&nbsp;·&nbsp;3 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%ec%a0%95%ec%9d%98" aria-label="정의">정의</a></li>
                <li>
                    <a href="#%ec%9d%b4%ed%95%b4" aria-label="이해">이해</a></li>
                <li>
                    <a href="#%ed%8c%8c%ec%9d%b4%ed%94%84%eb%9d%bc%ec%9d%b8" aria-label="파이프라인">파이프라인</a></li>
                <li>
                    <a href="#%ed%8c%8c%ec%9d%b4%ed%94%84%eb%9d%bc%ec%9d%b8-%ec%a0%95%eb%a6%ac" aria-label="파이프라인 정리">파이프라인 정리</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>컴퓨터 비전에 대해 원론적으로 접근해보면서 컴퓨터 비전에 대한 Depth를 넓히고자 한다 .</p>
<h2 id="정의"><code>정의</code><a hidden class="anchor" aria-hidden="true" href="#정의">#</a></h2>
<ol>
<li>
<p>디지털 이미지에서 정보를 추출하는 과학적인 영역
여기서 말하는 정보란 (Space, Location.. ) 등의 새로운 차원의 정보를 말한다.
따라서 RGB 혹은 RGBA 데이터로 새로운 차원의 정보를 추출하는 과학적인 영역이라고 해석할 수 있다</p>
</li>
<li>
<p>인간의 시야와 비슷한 시야 인지 능력을 구현하는 학문
인간의 지각 능력과 인지(해석)능력을 구분해 파이프라인을 구현하고 시야인지 능력을 구현하고자 하는 학문이라고 해석할 수 있다.</p>
</li>
</ol>
<p>아래 이미지를 통해 컴퓨터 비전이 포맷에 따라 어떻게 사용되는지 간략하게 파악 할 수 있다.</p>





  
  <img src="/images/vision_task_hucfe1fc509480f75c15cc4d19affe210a_85248_500x400_resize_box_3.png" width="500" height="400" />


<h2 id="이해"><code>이해</code><a hidden class="anchor" aria-hidden="true" href="#이해">#</a></h2>
<p>위 정의를 통해 컴퓨터 비전을 이해한다는 것은 인간의 시야 인지 능력을 컴퓨터로 구현하는 것을 이해해야한다 라고도 해석 할 수 있을 것이다. 그러면 순차적으로 어떤 것들을 이해해야 하는지 살펴보자.</p>
<ol>
<li><code>computer science</code> : memory, data structure 등 이미지를 처리하는 자료구조 및 메모리에 대한 기본적인 이해가 필요하다.</li>
<li><code>algorithm</code> : Filtering, Edge Detection 등 이미지 전처리를 위한 전통적인 알고리즘 기법을 이해해야한다.</li>
<li><code>machine learning</code>: 다양한 조건에서 나오는 이미지 패턴에 대한 일반화, 복잡한 연산을 통한 특징점 검출, 복잡한 이미지 패턴을 추출하기 위해 maching learning 알고리즘에 대한 기본적인 이해가 필요하다.</li>
</ol>
<p>그렇다면 machine learning은  컴퓨터 비전에서 어떻게 설계 되었을까?
인간의 sensing device와 interpreting device를 구분해서 해석하고 알고리즘으로 구현한 것이 machine learning의 기본 원리라고 이해 할 수 있다. 아래 인간의 시야 인지 파이프라인을 간략화한 그림을 통해 컴퓨터 비전이 어떻게 처리되는지 간단하게 이해해보자.</p>





  
  <img src="/images/perception_process_hu1fe37c277ce2723e3fb50233446a5928_231527_500x400_resize_box_3.png" width="500" height="400" />


<h2 id="파이프라인"><code>파이프라인</code><a hidden class="anchor" aria-hidden="true" href="#파이프라인">#</a></h2>
<p>빛이 인간의 눈에 들어오면 망막의 시세포가 빛을 신경 신호로 변환해준다.
여기서 변환된 신경 신호는 외측 슬상체를 통해 두 눈에서 들어온 신호를 결합하고 신호정보의 전처리와 필터링을 수행해준다.</p>
<p>전처리된 정보는 1차 시각야에서 윤곽을 추출해주는 방위 선택성 뉴런에 반응하게 된다. 방위 선택성 뉴런은 반응하는 방식에 따라 단순형 세포와 복잡형 세포로 나뉜다. 단순형 세포는 특정 위치와 특정 방향에  정확하게 위치한 선에 반응하고 복잡형 세포는 시야 어느 위치에 있든 특정 방향으로 기울어진 선에 반응하게 된다. 따라서 단순형 세포는 밝은 영역과 어두운 영역을 명확히 구분하는데 도움을 주고 복잡형 세포는 움직이는 물체나 선의 연속적인 변화를 인식하는데 도움을 준다. 딥러닝 알고리즘 중  CNN에서 Convolution 연산이 단순형 세포의 역활을 하고 Polling 연산이 복잡한 세포의 역활을 맡는다고도 생각 할 수 있다.</p>
<p>2차 시각야에서는 1차 시각야에서 추출된 윤곽 및 시각 특징들의 정보를  통합하고 제 4차 시각야로 보내준다.
(2차 시각야에서도 1차 시각야의 방위선택성 뉴런이 존재하여 이미지 윤곽을 추출하는 역활을 하지만 주요 역활은 시각 정보 특징들의 정보를 통합하는 것이라고 이해 할 수 있다.)</p>
<p>4차 시각야에서는 통합된 정보를 바탕으로 색상, 형태 ,물체를 인식하고 물체에 대한 이해 및 상위 피질과의 중계 역활을 한다. 따라서 인간의 interpreting device의 역활을 일부 수행한다고 볼 수 있다 .</p>
<h2 id="파이프라인-정리"><code>파이프라인 정리</code><a hidden class="anchor" aria-hidden="true" href="#파이프라인-정리">#</a></h2>
<p>정리해보면 다음과 같다.</p>
<ol>
<li>망막 : 빛을 신경 세포로 변환</li>
<li>외측 슬상체 : 신호 결합 및 전처리</li>
<li>1차 시각야 : 신호 정보에 대한 윤곽 및 시야정보 추출</li>
<li>2차 시각야: 시야 정보 통합 및 고차원 시야 정보 추출</li>
<li>4차 시각야: 고차원의 시야 정보를 바탕으로 색상, 형태, 물체 인식 및 분류 및 상위 피질과의 중계</li>
</ol>
<p>우리는 이것을 컴퓨터 프로세스에 대입해서 생각해 볼 수 있다.</p>
<ol>
<li>카메라 센서 및 광학 센서 ( 망막 ) : 빛을 전자 신호로 변환</li>
<li>아날로그-디지털 변환 ( 외측 슬상체 ): 전자 신호를 이미지 데이터로 변환 및 전처리</li>
<li>윤곽 추출 알고리즘  ( 1차 시각야 )  :  이미지 데이터에 윤곽 추출 알고리즘을 거쳐 윤곽 생성
ex) CNN, ResNet&hellip;</li>
<li>시야 정보 통합 알고리즘 ( 2차 시각야 ) : 추출한 정보 데이터를 통합하고 고차원의 시야정보 생성
ex) CNN, ResNet..</li>
<li>색상, 형태, 물체 인식 알고리즘 ( 4차 시각야 ) : 고차원의 시야정보로 물체를 인식 혹은 판별
ex) R-CNN, YOLO, CNN, GAN..</li>
</ol>
<p>위의 인지 프로세스를 이해했다면 아래 CNN의 과정을 대략적으로 이해 할 수 있을 것이다.</p>





  
  <img src="/images/cnn_image_hu2c712b0dacadadad9d9be5429b71e4e3_31852_800x400_resize_box_3.png" width="800" height="400" />


<p>다음시간에는 딥러닝 및 머신러닝의 기본 원리, 학습의 의미를 표현하고 있는 Linear Regression에 대해 알아보고자 한다.</p>
<p>참고 : <a href="http://vision.stanford.edu/teaching/cs131_fall1718/files/cs131-class-notes.pdf">standford computer vision lab</a>,<a href="https://www.hellot.net/mobile/article.html?no=85491">helloT</a></p>
<p>이미지 출처 : <a href="https://www.analyticsvidhya.com/blog/2021/06/image-processing-using-cnn-a-beginners-guide/">Analytics Vidhya</a>,
<a href="https://www.analyticsvidhya.com/blog/2021/06/image-processing-using-cnn-a-beginners-guide/">standford computer vision lab</a>,
<a href="https://www.hellot.net/mobile/article.html?no=85491">helloT</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://garfield0xff.github.io/posts/gradient-descent/">
    <span class="title">« Prev</span>
    <br>
    <span>Gradient Descent</span>
  </a>
  <a class="next" href="https://garfield0xff.github.io/posts/linear-regression/">
    <span class="title">Next »</span>
    <br>
    <span>Linear Regression</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>2024 Kim Gyujin</span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
